{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic ANN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbocTbLuimXUXdPtTv97BU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pin2gupta/Deep-Learning/blob/main/Basic_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOn_YrOdNzM9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf3P40sZCjGG"
      },
      "source": [
        "## What is Neural Network?\n",
        "Neural Networks are the represntation of the Human brain. These neurons are connected to each other and forms a network. The connection is a transformation of the infomation to many layers to make a thing \"drive a car\"\n",
        "\n",
        "The entire neural network works on simple phenomena; we provide input variables, the next level of neural network which is also referred as hidden layer perfom some mathematical operation and produces the reuslt to the next level. The final layer is the output layer which is actually the desired result. \n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1weA60u0H2SAKtUfQhePKWDNcjlrnKXNA)\n",
        "\n",
        "                        Figure - 1\n",
        "\n",
        "If there are more than one hiden layer then it is referred as Deep Neural Network as in the above example. \n",
        "\n",
        "The Neural Networks are read from left to right. The internal layers are connected to one before and one after layers. If the layer is n then it will be ocnnected to n-1 or n+1 layer. \n",
        "\n",
        "## How the neurons operates?\n",
        "\n",
        "The basic actors of neuron network are Input Layer, Hidden Layer Weights, Bias, Activation function and Output Layer. \n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1SMlT7l0pbctnFmCSwsUoWIalGiyaNkvy)\n",
        "\n",
        "\n",
        "                          Figure - 2\n",
        "\n",
        "\n",
        "**Input Layer** are the variables which we feed to the network. The number of neurons are the number of inputs we feed to the network. There is no computation being done on input layer. They are usually represted as $x_{1},x_{2},x_{3}....x_{n}$\n",
        "\n",
        "**Hidden Layer** is the layer/s between input and putput layer. The hidden layers are hte layers where all the computation, processing is performed. They derive the complext relationship between Input and Output layer. They identifies the data pattersn in the dataset. They are also responsible for extracting inportant features and eiather transforming it to the next layer or to the output layer.\n",
        "\n",
        "The number of hidden layers can be choosen based on the complexity of the problem. \n",
        "\n",
        "**Output layer** is the result layer. The number of output layer is based on the type of problem we want our network to resolve. \n",
        "\n",
        "If it is a *binary classification*, then the number of neurons in the output layer is one that tells us which class the input belongs to. \n",
        "\n",
        "If it is a *multi-class classification* say, with five classes, and if we want to get the probability of each class as an output, then the number of neurons in the output layer is five, each emitting the probability. \n",
        "\n",
        "If it is a *regression* problem, then we have one neuron in the output layer.\n",
        "\n",
        "**Weights** The weights are used to strengthening the inputs by multiplying it to the inputs. These are the only values which could be changed during the learning process. The reason of multipying is to provide more weightage to the input variable. The more important the input variable , higher the weight values. \n",
        "The wieights are represeted as $w_{1},w_{2},w_{3}....w_{n}$\n",
        "\n",
        "Sum the weights after it has been multipied which is represnted as Z\n",
        " \n",
        " $z=x_{1}*w_{1}+x_{2}*w_{2}+x_{3}*w_{3}.....x_{n}*w_{n}$\n",
        "\n",
        " This is nothing but hte equation of straight line\n",
        "\n",
        " $z=mx+c$ \n",
        " where *m* is the weight (coefieceint), *x* is the input and c is the bias (intercept). \n",
        "\n",
        "**Bias** is the constant which is added to the adjust the output of the neuron. The values is choosen to shift the activation function to either right or left to delay the triggering of the activation function. \n",
        "If it is absent then the line will pass through (0,0) and it will be a poorer fit. \n",
        "\n",
        "$z=x_{1}*w_{1}+x_{2}*w_{2}+x_{3}*w_{3}.....x_{n}*w_{n} + b$\n",
        "\n",
        "**Activation Function** The activation function is the non-linear transformation that we do over the input beofre sending it to the next layer of neurons or finalizing the output. \n",
        "The neurons does not know the bounds of the value. So to decide whether the output result should be fired or not , we use activation function. \n",
        "\n",
        "Hence, this is all neurons does; it takes all values from connected neurons multiplied by their respective weights; add them amd apply an activation function. The neuron is ready to send the value to the other layer. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPyx-TxdCx6X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}