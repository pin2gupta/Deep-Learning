{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Epochs & Iteration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfwIYO6SRyEqxv7yRBpFBK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pin2gupta/Deep-Learning/blob/main/Basics/Epochs_%26_Iteration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li7djyNqOlEM"
      },
      "source": [
        "## What is Batch ,Epochs and iteration?\n",
        "\n",
        "An **Epochs** is a term used in ML that refers to the number of pass the machine learning alogorithm has made over the entire training dataset. \n",
        "\n",
        "A **Batch Size** is the number of samples that usually pass through the neural network at one time. \n",
        "\n",
        "An **iteration** is the number of batch passes takes to complete the entire dataset \n",
        "\n",
        "For Example, if we have 1000 training dataset and batch size is 500 then we have 2 iteration to complet 1 epochs.  \n",
        "\n",
        "One or more batches may be generated from a training dataset. Batch gradient descent is a learning algorithm that uses all training samples to generate a single batch. The learning algorithm is called stochastic gradient descent when the batch size is one sample. The learning algorithm is called mini-batch gradient descent when the batch size is more than one sample and less than the training dataset's size.\n",
        "\n",
        "**Batch Gradient Descent.** Batch Size = Size of Training Set\n",
        "\n",
        "**Stochastic Gradient Descent.** Batch Size = 1\n",
        "\n",
        "**Mini-Batch Gradient Descent.** 1 < Batch Size < Size of Training Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7P7vraEPhFP"
      },
      "source": [
        "## What is Cost Function and loss function?\n",
        "**Loss function** is the measure of how wrong the model is in terms of it abilty to estimate the relationshiop between X and Y. Loss function is calculate many times during the trianing cycle. An optimizer is used to minimze the loss function. \n",
        "There are two types of losses:\n",
        "- Regression Losses \n",
        " - Mean Square Error/Quadratic Loss/L2 Loss\n",
        " - Mean Absolute Error/L1 Loss\n",
        " - Mean Bias Error\n",
        "- Classification Losses\n",
        " - Hinge Loss/Multi class SVM Loss\n",
        " - Cross Entropy Loss/Negative Log Likelihood\n",
        "\n",
        "**Ref:**[Common Loss functions in machine learning](https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23)\n",
        "\n",
        "**Cost Function** also refers as error function. This deals with the penality for a number of training sets or the complete batch. This can also define as sum of the loss function plus some model compexity penality. \n",
        "The types of cost functions are:\n",
        "- MSE , MAE and MBE\n",
        "- Cross Entropy Cose\n",
        "- Exponetial Cost\n",
        "-a probability of generating training set in maximum likelihood approach is a well defined objective function,\n",
        "\n",
        "**Ref:** [A List of Cost Function used in NN](https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications)\n",
        "\n",
        "**Objective Function** a probability of generating training set in maximum likelihood approach is an objective function,\n",
        "\n",
        "A loss function is a part of cost function which is a type of an objective function. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3uSuCzePg5P"
      },
      "source": [
        "## What is Optimization?"
      ]
    }
  ]
}