{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Activation Function.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMP7e5VZxNMm+zaFd76MS8F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pin2gupta/Deep-Learning/blob/main/Basics/Copy_of_Activation_Function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFNZ1ho8jkCI"
      },
      "source": [
        "## What is activation functions?\n",
        "The activation functions are the functions which decides whether the current output of the neuron should be triggered to the next cell or not. It also converts the output to new form that can be accepted to the next layer/neuron.\n",
        "\n",
        "## Why needed?\n",
        "- It is used to add non-linerity into the neural network. \n",
        "- They also help in keeping the value of the output from the neuron restricted to a certain limit as needed. \n",
        "\n",
        "Imagine a neural network without the activation functions. In that case, every neuron will only be performing a linear transformation on the inputs using the weights and biases. Although linear transformations make the neural network simpler, but this network would be less powerful and will not be able to learn the complex patterns from the data\n",
        "\n",
        "\n",
        "## What are types of activation function?\n",
        "####**Heaviside Step Function** \n",
        "This is one of the common activation function in the neural network. \n",
        "\n",
        "\"The function produces 1 (or true) when input passes threshold limit whereas it produces 0 (or false) when input does not pass threshold.\" Since it produces binary results , it is sometimes called binary step function. \n",
        "                \n",
        "                f(x) = 1, if x > 0\n",
        "                f(x) = 0, if x < 0\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1uZDfxRCUHjP4M1DTpoMBkYtBWJW-6-Pj)\n",
        "\n",
        "**Problem with Step Function:** \n",
        "\n",
        "the gradient of the function became zero. This is because there is no component of x in the binary step function.\n",
        "Instead we define Linear Function.\n",
        "\n",
        "###**Linear Activation Function**\n",
        "The function is defined as \n",
        "\n",
        "f(x) = ax\n",
        "here the activation is directly proportional to the input. The variable \"a\" in case could be any constant value. \n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1XpYemvoA31_d_dAFDOtIID8jFlMdKOmW)\n",
        "\n",
        "Here the gradient does not become zero, but it is a constant which does not depend upon the input value of x at all. This implies that the weights and biases will be updated during the backpropagation process but the updating factor would be the same.\n",
        "\n",
        "In this scenario, the neural network will not really improve the error since the gradient is the same for every iteration. The network will not be able to train well and capture the complex patterns from the data. Hence, linear function might be ideal for simple tasks where interpretability is highly desired.\n",
        "\n",
        "The other activation function as describe in the picture\n",
        "![](https://drive.google.com/uc?export=view&id=1s91Eg7DxA20DGEV03LwLuQqIgTccQnrh)\n",
        "\n",
        "There is \n",
        "\n",
        "###**Sigmoid :** \n",
        "\n",
        "\n",
        "## How to choose different activation function?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9ptOz_lhC5W"
      },
      "source": [
        "### **References:**\n",
        "1. [Everything you need to know about “Activation Functions” in Deep learning models ](https://towardsdatascience.com/everything-you-need-to-know-about-activation-functions-in-deep-learning-models-84ba9f82c253)\n",
        "2. [Deep Learning cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning)\n"
      ]
    }
  ]
}